{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: Predicting Movie Review Sentiment with Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative text sample: a series of escapades demonstrating the adage that what is good for the goose is also good for the g\n",
      "Positive text sample: this quiet , introspective and entertaining independent is worth seeking . a source of high hilarity\n",
      "\n",
      "Negative Counts:\n",
      "Counter({'a': 9, 'hard': 6, 'time': 6, 'sitting': 6, 'through': 6, 'this': 6, 'one': 6, 'of': 5, 'have': 5, ',': 4, '.': 4, 'would': 4, 'the': 3, 'is': 2, 'good': 2, 'for': 2, 'which': 2, 'i': 2, 'suspect': 2, 'series': 1, 'escapades': 1, 'demonstrating': 1, 'adage': 1, 'that': 1, 'what': 1, 'goose': 1, 'also': 1, 'gander': 1, 'some': 1, 'occasionally': 1, 'amuses': 1, 'but': 1, 'none': 1, 'amounts': 1, 'to': 1, 'much': 1, 'story': 1, 'even': 1, 'fans': 1, 'ismail': 1, 'merchant': 1, \"'s\": 1, 'work': 1, 'shakespearean': 1, 'tragedy': 1})\n",
      "\n",
      "Positive Counts:\n",
      "Counter({'and': 15, 'a': 14, ',': 10, '.': 8, 'of': 6, 'is': 5, 'this': 4, 'sweet': 4, 'modest': 4, 'ultimately': 4, 'winning': 4, 'story': 4, 'the': 4, 'be': 3, 'one': 3, 'positively': 3, 'thrilling': 3, 'combination': 3, 'ethnography': 3, 'all': 3, 'intrigue': 3, 'betrayal': 3, 'deceit': 3, 'murder': 3, 'shakespearean': 2, 'tragedy': 2, 'or': 2, 'juicy': 2, 'soap': 2, 'opera': 2, 'welcome': 2, 'relief': 2, 'from': 2, 'baseball': 2, 'movies': 2, 'that': 2, 'try': 2, 'too': 2, 'hard': 2, 'to': 2, 'mythic': 2, 'quiet': 1, 'introspective': 1, 'entertaining': 1, 'independent': 1, 'worth': 1, 'seeking': 1, 'source': 1, 'high': 1, 'hilarity': 1, 'i': 1, 'still': 1, 'like': 1, 'moonlight': 1, 'mile': 1, 'better': 1, 'judgment': 1, 'damned': 1, 'performances': 1, 'are': 1, 'an': 1, 'absolute': 1, 'joy': 1})\n"
     ]
    }
   ],
   "source": [
    "# A nice python class that lets you count how many times items occur in a list\n",
    "from collections import Counter\n",
    "import csv\n",
    "import re\n",
    "\n",
    "# Read in the training data\n",
    "with open(\"Data/movie_sentiment_train.csv\", 'r') as file:\n",
    "    reviews = list(csv.reader(file))\n",
    "\n",
    "#print(reviews)\n",
    "    \n",
    "def get_text(reviews, score):\n",
    "      # Join together the text in the reviews for a particular tone.\n",
    "      # We lowercase to avoid \"Not\" and \"not\" being seen as different words, for example.\n",
    "    for r in reviews:\n",
    "        return \" \".join([r[0].lower() for r in reviews if r[1] == str(score)])\n",
    "\n",
    "def count_text(text):\n",
    "    # Split text into words based on whitespace. Simple but effective\n",
    "    words = re.split(\"\\s+\", text)\n",
    "    # Count up the occurence of each word\n",
    "    return Counter(words)\n",
    "\n",
    "negative_text = get_text(reviews, -1)\n",
    "positive_text = get_text(reviews, 1)\n",
    "\n",
    "# Generate word counts for negative tone\n",
    "list_negative_counts = count_text(negative_text)\n",
    "\n",
    "# Generate word counts for positive tone\n",
    "list_positive_counts = count_text(positive_text)\n",
    "\n",
    "print(\"Negative text sample: {0}\".format(negative_text[:100]))\n",
    "print(\"Positive text sample: {0}\".format(positive_text[:100]))\n",
    "print()\n",
    "\n",
    "print(\"Negative Counts:\",)\n",
    "print(list_negative_counts)\n",
    "print()\n",
    "print(\"Positive Counts:\")\n",
    "print(list_positive_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Review => A series of escapades demonstrating the adage that what is good for the goose is also good for the gander , some of which occasionally amuses but none of which amounts to much of a story .\n",
      "\n",
      "Negative prediction => 1.5336056959847352e-45\n",
      "\n",
      "Positive prediction => 3.9540827896477066e-55\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "def get_y_count(score):\n",
    "  # Compute the count of each classification occuring in the data.\n",
    "  return len([r for r in reviews if r[1] == str(score)])\n",
    "\n",
    "# We need these counts to use for smoothing when computing the prediction.\n",
    "positive_review_count = get_y_count(1)\n",
    "negative_review_count = get_y_count(-1)\n",
    "#print(\"Positive Review Count = \", positive_review_count)\n",
    "#print(\"Negative Review Count = \", negative_review_count)\n",
    "\n",
    "# These are the class probabilities (we saw them in the formula as P(y)).\n",
    "prob_positive = positive_review_count / len(reviews)\n",
    "prob_negative = negative_review_count / len(reviews)\n",
    "#print(\"prob_positive = \", positive_review_count, \"/\", len(reviews), \" = \", prob_positive)\n",
    "#print(\"prob_negative = \", negative_review_count, \"/\", len(reviews), \" = \", prob_negative)\n",
    "\n",
    "def make_class_prediction(text, counts, class_prob, class_count):\n",
    "  prediction = 1\n",
    "  text_counts = Counter(re.split(\"\\s+\", text))\n",
    "  #print(\"Text Counts = \", text_counts)\n",
    "  for word in text_counts:\n",
    "      # For every word in the text, we get the number of times that word occured in the reviews for a given class, add 1 to smooth the value, and divide by the total number of words in the class (plus the class_count to also smooth the denominator).\n",
    "      # Smoothing ensures that we don't multiply the prediction by 0 if the word didn't exist in the training data.\n",
    "      # We also smooth the denominator counts to keep things even.\n",
    "      #print(text_counts.get(word))\n",
    "      prediction *=  text_counts.get(word) * ((counts.get(word, 0) + 1) / (sum(counts.values()) + class_count))\n",
    "  # Now we multiply by the probability of the class existing in the documents.\n",
    "  return prediction * class_prob\n",
    "\n",
    "# As you can see, we can now generate probabilities for which class a given review is part of.\n",
    "# The probabilities themselves aren't very useful -- we make our classification decision based on which value is greater.\n",
    "print()\n",
    "print(\"Review => {0}\".format(reviews[0][0]))\n",
    "print()\n",
    "print(\"Negative prediction => {0}\".format(make_class_prediction(reviews[0][0], list_negative_counts, prob_negative, negative_review_count)))\n",
    "print()\n",
    "print(\"Positive prediction => {0}\".format(make_class_prediction(reviews[0][0], list_positive_counts, prob_positive, positive_review_count)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def make_decision(text, make_class_prediction):\n",
    "    # Compute the negative and positive probabilities.\n",
    "    negative_prediction = make_class_prediction(text, negative_counts, prob_negative, negative_review_count)\n",
    "    positive_prediction = make_class_prediction(text, positive_counts, prob_positive, positive_review_count)\n",
    "\n",
    "    # We assign a classification based on which probability is greater.\n",
    "    if negative_prediction > positive_prediction:\n",
    "      return -1\n",
    "    return 1\n",
    "\n",
    "with open(\"Data/movie_sentiment_test.csv\", 'r') as file:\n",
    "    test = list(csv.reader(file))\n",
    "\n",
    "predictions = [make_decision(r[0], make_class_prediction) for r in test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC of the predictions: 0.5\n"
     ]
    }
   ],
   "source": [
    "actual = [int(r[1]) for r in test]\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "# Generate the roc curve using scikit-learn.\n",
    "fpr, tpr, thresholds = metrics.roc_curve(actual, predictions, pos_label=1)\n",
    "\n",
    "# Measure the area under the curve.  The closer to 1, the \"better\" the predictions.\n",
    "print(\"AUC of the predictions: {0}\".format(metrics.auc(fpr, tpr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial naive bayes AUC: 0.75\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import metrics\n",
    "\n",
    "# Generate counts from text using a vectorizer.  There are other vectorizers available, and lots of options you can set.\n",
    "# This performs our step of computing word counts.\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "train_features = vectorizer.fit_transform([r[0] for r in reviews])\n",
    "test_features = vectorizer.transform([r[0] for r in test])\n",
    "\n",
    "# Fit a naive bayes model to the training data.\n",
    "# This will train the model using the word counts we computer, and the existing classifications in the training set.\n",
    "nb = MultinomialNB()\n",
    "nb.fit(train_features, [int(r[1]) for r in reviews])\n",
    "\n",
    "# Now we can use the model to predict classifications for our test features.\n",
    "predictions = nb.predict(test_features)\n",
    "\n",
    "# Compute the error.  It is slightly different from our model because the internals of this process work differently from our implementation.\n",
    "fpr, tpr, thresholds = metrics.roc_curve(actual, predictions, pos_label=1)\n",
    "print(\"Multinomial naive bayes AUC: {0}\".format(metrics.auc(fpr, tpr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
